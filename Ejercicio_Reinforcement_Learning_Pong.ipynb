{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje por Refuerzo: el Pong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El artículo completo en el blog [Aprende Machine Learning](http://www.aprendemachinelearning.com) en Español.\n",
    "\n",
    "Crearemos el juego del pong con interface gráfica de Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Agente deberá aprender a jugar sólo mediante premios y castigos.\n",
    "\n",
    "Crearemos las clases:\n",
    "\n",
    "* Agente: implementará el algoritmo de QLearning\n",
    "* Environment: será nuestro tablero de juego\n",
    "\n",
    "Y crearemos una función para comenzar a jugar, donde entrenará iterando miles de partidas de pong.\n",
    "\n",
    "Finalmente, ejecutarmos 1 partida con el agente ya entrenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T15:27:48.216441Z",
     "start_time": "2020-12-22T15:27:48.206167Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from math import ceil,floor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T08:51:27.697276Z",
     "start_time": "2020-12-23T08:51:27.661385Z"
    }
   },
   "outputs": [],
   "source": [
    "class PongAgent:\n",
    "    \n",
    "    def __init__(self, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
    "\n",
    "        # Creamos la tabla de politicas\n",
    "        if policy is not None:\n",
    "            self._q_table = policy\n",
    "        else:\n",
    "            position = list(game.positions_space.shape)\n",
    "            position.append(len(game.action_space))\n",
    "            self._q_table = np.zeros(position)\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ratio_explotacion = ratio_explotacion\n",
    "\n",
    "    def get_next_step(self, state, game):\n",
    "        \n",
    "        # Damos un paso aleatorio...\n",
    "        next_step = np.random.choice(list(game.action_space))\n",
    "        \n",
    "        # o tomaremos el mejor paso...\n",
    "        if np.random.uniform() <= self.ratio_explotacion:\n",
    "            # tomar el maximo\n",
    "            idx_action = np.random.choice(np.flatnonzero(\n",
    "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
    "                ))\n",
    "            next_step = list(game.action_space)[idx_action]\n",
    "\n",
    "        return next_step\n",
    "\n",
    "    # actualizamos las politicas con las recompensas obtenidas\n",
    "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
    "        idx_action_taken =list(game.action_space).index(action_taken)\n",
    "\n",
    "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
    "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
    "\n",
    "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
    "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
    "        if reached_end:\n",
    "            future_max_q_value = reward_action_taken #maximum reward\n",
    "\n",
    "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
    "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
    "    \n",
    "    def print_policy(self):\n",
    "        for row in np.round(self._q_table,1):\n",
    "            for column in row:\n",
    "                print('[', end='')\n",
    "                for value in column:\n",
    "                    print(str(value).zfill(5), end=' ')\n",
    "                print('] ', end='')\n",
    "            print('')\n",
    "            \n",
    "    def get_policy(self):\n",
    "        return self._q_table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T08:51:29.012993Z",
     "start_time": "2020-12-23T08:51:28.966762Z"
    }
   },
   "outputs": [],
   "source": [
    "class PongEnvironment:\n",
    "    \n",
    "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
    "        \n",
    "        self.action_space = ['Arriba','Abajo']\n",
    "        \n",
    "        self._step_penalization = 0\n",
    "        \n",
    "        self.state = [0,0,0]\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.dx = movimiento_px\n",
    "        self.dy = movimiento_px\n",
    "        \n",
    "        filas = ceil(height_px/movimiento_px)\n",
    "        columnas = ceil(width_px/movimiento_px)\n",
    "        \n",
    "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
    "                                                  for y in range(filas)] \n",
    "                                                     for x in range(filas)])\n",
    "\n",
    "        self.lives = max_life\n",
    "        self.max_life=max_life\n",
    "        \n",
    "        self.x = randint(int(width_px/2), width_px) \n",
    "        self.y = randint(0, height_px-10)\n",
    "        \n",
    "        self.player_alto = int(height_px/4)\n",
    "\n",
    "        self.player1 = self.player_alto  # posic. inicial del player\n",
    "        \n",
    "        self.score = 0\n",
    "        \n",
    "        self.width_px = width_px\n",
    "        self.height_px = height_px\n",
    "        self.radio = 2.5\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_reward = 0\n",
    "        self.state = [0,0,0]\n",
    "        self.lives = self.max_life\n",
    "        self.score = 0\n",
    "        self.x = randint(int(self.width_px/2), self.width_px) \n",
    "        self.y = randint(0, self.height_px-10)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, animate=False):\n",
    "        self._apply_action(action, animate)\n",
    "        done = self.lives <=0 # final\n",
    "        reward = self.score\n",
    "        reward += self._step_penalization\n",
    "        self.total_reward += reward\n",
    "        return self.state, reward , done\n",
    "\n",
    "    def _apply_action(self, action, animate=False):\n",
    "        \n",
    "        if action == \"Arriba\":\n",
    "            self.player1 += abs(self.dy)\n",
    "        elif action == \"Abajo\":\n",
    "            self.player1 -= abs(self.dy)\n",
    "            \n",
    "        self.avanza_player()\n",
    "\n",
    "        self.avanza_frame()\n",
    "\n",
    "        if animate:\n",
    "            clear_output(wait=True);\n",
    "            fig = self.dibujar_frame()\n",
    "            plt.show()\n",
    "\n",
    "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
    "    \n",
    "    def detectaColision(self, ball_y, player_y):\n",
    "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def avanza_player(self):\n",
    "        if self.player1 + self.player_alto >= self.height_px:\n",
    "            self.player1 = self.height_px - self.player_alto\n",
    "        elif self.player1 <= -abs(self.dy):\n",
    "            self.player1 = -abs(self.dy)\n",
    "\n",
    "    def avanza_frame(self):\n",
    "        self.x += self.dx\n",
    "        self.y += self.dy\n",
    "        if self.x <= 3 or self.x > self.width_px:\n",
    "            self.dx = -self.dx\n",
    "            if self.x <= 3:\n",
    "                ret = self.detectaColision(self.y, self.player1)\n",
    "\n",
    "                if ret:\n",
    "                    self.score = 10\n",
    "                else:\n",
    "                    self.score = -10\n",
    "                    self.lives -= 1\n",
    "                    if self.lives>0:\n",
    "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
    "                        self.y = randint(0, self.height_px-10)\n",
    "                        self.dx = abs(self.dx)\n",
    "                        self.dy = abs(self.dy)\n",
    "        else:\n",
    "            self.score = 0\n",
    "\n",
    "        if self.y < 0 or self.y > self.height_px:\n",
    "            self.dy = -self.dy\n",
    "\n",
    "    def dibujar_frame(self):\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        a1 = plt.gca()\n",
    "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
    "        a1.set_ylim(-5, self.height_px+5)\n",
    "        a1.set_xlim(-5, self.width_px+5)\n",
    "\n",
    "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
    "        a1.add_patch(circle);\n",
    "        a1.add_patch(rectangle)\n",
    "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
    "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
    "        if self.lives <=0:\n",
    "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
    "        elif self.total_reward >= 1000:\n",
    "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T08:52:11.246599Z",
     "start_time": "2020-12-23T08:52:11.234921Z"
    }
   },
   "outputs": [],
   "source": [
    "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
    "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
    "\n",
    "    if game is None:\n",
    "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
    "        \n",
    "    if learner is None:\n",
    "        print(\"Begin new Train!\")\n",
    "        learner = PongAgent(discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
    "\n",
    "    max_points= -9999\n",
    "    first_max_reached = 0\n",
    "    total_rw=0\n",
    "    steps=[]\n",
    "\n",
    "    for played_games in range(0, rounds):\n",
    "        state = game.reset()\n",
    "        reward, done = None, None\n",
    "        \n",
    "        itera=0\n",
    "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
    "            old_state = np.array(state)\n",
    "            next_action = learner.get_next_step(state, game)\n",
    "            state, reward, done = game.step(next_action, animate=animate)\n",
    "            if rounds > 1:\n",
    "                learner.update(game, old_state, next_action, reward, state, done)\n",
    "            itera+=1\n",
    "        \n",
    "        steps.append(itera)\n",
    "        \n",
    "        total_rw+=game.total_reward\n",
    "        if game.total_reward > max_points:\n",
    "            max_points=game.total_reward\n",
    "            first_max_reached = played_games\n",
    "        \n",
    "        if played_games %500==0 and played_games >1 and not animate:\n",
    "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
    "                \n",
    "    if played_games>1:\n",
    "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
    "        \n",
    "    #learner.print_policy()\n",
    "    \n",
    "    return learner, game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T08:56:22.498041Z",
     "start_time": "2020-12-23T08:54:49.878072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin new Train!\n",
      "-- Partidas[ 500 ] Avg.Puntos[ 10 ]  AVG Steps[ 205 ] Max Score[ 150 ]\n",
      "-- Partidas[ 1000 ] Avg.Puntos[ 20 ]  AVG Steps[ 238 ] Max Score[ 190 ]\n",
      "-- Partidas[ 1500 ] Avg.Puntos[ 26 ]  AVG Steps[ 260 ] Max Score[ 260 ]\n",
      "-- Partidas[ 2000 ] Avg.Puntos[ 30 ]  AVG Steps[ 274 ] Max Score[ 360 ]\n",
      "-- Partidas[ 2500 ] Avg.Puntos[ 32 ]  AVG Steps[ 279 ] Max Score[ 370 ]\n",
      "-- Partidas[ 3000 ] Avg.Puntos[ 35 ]  AVG Steps[ 289 ] Max Score[ 420 ]\n",
      "-- Partidas[ 3500 ] Avg.Puntos[ 38 ]  AVG Steps[ 300 ] Max Score[ 520 ]\n",
      "-- Partidas[ 4000 ] Avg.Puntos[ 41 ]  AVG Steps[ 310 ] Max Score[ 540 ]\n",
      "-- Partidas[ 4500 ] Avg.Puntos[ 43 ]  AVG Steps[ 318 ] Max Score[ 540 ]\n",
      "Partidas[ 4999 ] Avg.Puntos[ 45 ] Max score[ 540 ] en partida[ 3706 ]\n"
     ]
    }
   ],
   "source": [
    "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T13:59:41.374994Z",
     "start_time": "2020-12-23T13:50:02.750024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner2 = PongAgent(policy=learner.get_policy())\n",
    "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
    "player = play(rounds=1, learner=learner2, game=game, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
